# Deep Learning for Detecting Building Defects Using Convolutional Neural Networks
Traditional methods for this type of work commonly comprise of engaging building surveyors to undertake a condition assessment which involves a lengthy site inspection to produce a systematic recording of the physical condition of the building elements, including cost estimates of immediate and projected long-term costs of renewal, repair and maintenance of the building. Current asset condition assessment procedures are extensively time consuming, laborious, and expensive and pose health and safety threats to surveyors, particularly at height and roof levels which are difficult to access. In this project we aims at evaluating the application of convolutional neural networks (CNN) towards an automated detection and localisation of key building defects, e.g., mould, deterioration, and stain, from images. The proposed model is based on pre-trained CNN classifier of VGG-16 (later compaired with ResNet-50, and Inception models), with class activation mapping (CAM) for object localisation.

![cnvnet](https://user-images.githubusercontent.com/76107657/118636986-37f65000-b7cd-11eb-89d8-6d5a4af6fa13.png)

### Transfer learning
An important technique in deep learning which is used to solve the problem of insufficient training data by transferring knowledge from one domain to another. A good practice in transferring knowledge, is to use a well-structured network which is pre-trained on a large data and use its knowledge as a weight initialiser for a new network. For example, using pre-trained VGGNET on ImageNet dataset which contains 14 million annotated images and contains more than 20,000 categories). Implementing transfer learning can be in one of two ways:
#### Feature extractor
In this arrangement, the fully-connected layers in the pre-trained network are removed and the neural network is treated as a fixed feature extractor.  In the case of the VGGNET, the fully-connected layers generates 1000 different classes. The earlier layers (convolutional) in the pre-trained network are then trained on the new dataset as feature extractor only. For each input image, the VGGNET computes a 4096-D feature map which is then passed to the ReLU function In order to reduce the number of features required for later computation.  With all feature maps extracted from all the images in the training dataset, a Softmax classifier with n-classes (the number of classes in the new dataset) is placed on top of the pre-trained network and trained again on the new dataset.
#### Fine-tuning
In addition to replacing a new Softmax classifier on top of the pre-trained network and retraining it on the new dataset, in this scenario, it is possible to fine-tune a pre-trained network by using some of the earlier (convolution) layers as feature extractor while retrain the higher-level parts of the network on the new dataset.  Since earlier convolution layers in a network are able to detect generic features (e.g. edge detectors or colour blob detectors), this could be very useful to many tasks. Later convolution layers, however, are more specific to the details of the classes contained in the original dataset. A fine-tuned network, hence, exploits the capabilities of early layers in pre-trained network to extract generic feature, while training later layers and the classifier on the more specific details of the new dataset.

![tl](https://user-images.githubusercontent.com/76107657/118636982-362c8c80-b7cd-11eb-9835-fe6d626119bd.png)



### Localistion Problem
To address the localisation problem we integrated the Gradient-weighted Class Activation Mapping (Grad-CAM) with our network. The Grad-CAM is a technique that uses the gradient of an object under consideration entering the final convolutional layer of the ConvNet to produces a coarse localisation map which highlights the most significant regions in the image for predicting the class of this image.

![CAM) for object localisation](https://github.com/obu-sobe/Defects_Detection/blob/main/images/defects.png)

![d4](https://user-images.githubusercontent.com/76107657/118637791-16499880-b7ce-11eb-8018-6ba8a1910758.png)
![d3](https://user-images.githubusercontent.com/76107657/118637796-177ac580-b7ce-11eb-8250-a0c5e7d0b526.png)
![d2](https://user-images.githubusercontent.com/76107657/118637803-18abf280-b7ce-11eb-9aad-131fec15e40a.png)
![d1](https://user-images.githubusercontent.com/76107657/118637808-19448900-b7ce-11eb-8d20-10a1e01d6867.png)


### Conclusions and Further Work
As part of our research activities on automated detection and localisation of key building defects, in this paper, we proposed a deep learning based method for detecting three categories of defects; mould, stain and paint deterioration. For our classification problem, we applied a fine-tuning transfer learning to a VGG-16 network pre-trained on ImageNet. A total number 1,943 images cropped into 224x 224 thumbnails were used as our dataset. The data was labelled into three main categories, mould, stain and paint deterioration which includes peeling, blistering, flacking, and crazing. The total number of images used for training data is 1394; mould (534 images), stain (449), paint deterioration (411).  For the validation set, a 20% of the training data was a randomly chosen. In order to obtain sufficient robustness, a broad range of image augmentations were applied to the training and validation sets.  After 50 epochs the network recorded an accuracy of %96.63 with 0.0914 loss on the training set and %97.50 with 0.0588 loss on the validation. The robustness of our network was evaluated on a separate set of 549 images, 183 image for each class. The evaluation test showed a consistence performance with %93 of images containing mould and %80 images containing both stain and deterioration were accurately classified. The final accuracy recorded after completing the validation test was 91.43%. To address the localisation problem, we integrated the gradient weighted class activation mapping (Grad-CAM) which was able to allocate defects with high precision. The overall performance of the proposed network has shown high reliability and robustness in classifying and localising defects. As part of our future work, the network will be developed to detect other defects including cracks, brick slips, flashings, structural movements, spalling and corrosion in addition to all types of paint deterioration such as peeling, blistering, flacking, blooming, chalking, and crazing. This work will also be combined with work on real-time detection of defects using vision sensors including drones. Our long-term vision also include plans to create a large, open source database of different construction defects which will help world-wide research on damage assessment. 

